{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 756,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.10582010582010581,
      "grad_norm": 0.783671498298645,
      "learning_rate": 5.399999999999999e-05,
      "loss": 3.975,
      "step": 20
    },
    {
      "epoch": 0.21164021164021163,
      "grad_norm": 0.7443432807922363,
      "learning_rate": 0.00011399999999999999,
      "loss": 3.6655,
      "step": 40
    },
    {
      "epoch": 0.31746031746031744,
      "grad_norm": 1.1304214000701904,
      "learning_rate": 0.00017399999999999997,
      "loss": 3.4962,
      "step": 60
    },
    {
      "epoch": 0.42328042328042326,
      "grad_norm": 0.9731800556182861,
      "learning_rate": 0.000234,
      "loss": 3.1745,
      "step": 80
    },
    {
      "epoch": 0.5291005291005291,
      "grad_norm": 1.1039698123931885,
      "learning_rate": 0.000294,
      "loss": 3.1394,
      "step": 100
    },
    {
      "epoch": 0.6349206349206349,
      "grad_norm": 1.2782139778137207,
      "learning_rate": 0.0002917682926829268,
      "loss": 3.0026,
      "step": 120
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 1.101792573928833,
      "learning_rate": 0.00028262195121951216,
      "loss": 3.1161,
      "step": 140
    },
    {
      "epoch": 0.8465608465608465,
      "grad_norm": 1.2044857740402222,
      "learning_rate": 0.0002734756097560975,
      "loss": 2.9782,
      "step": 160
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 0.866916298866272,
      "learning_rate": 0.0002643292682926829,
      "loss": 3.156,
      "step": 180
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.705085277557373,
      "eval_runtime": 2.4038,
      "eval_samples_per_second": 17.472,
      "eval_steps_per_second": 8.736,
      "step": 189
    },
    {
      "epoch": 1.0582010582010581,
      "grad_norm": 1.2833106517791748,
      "learning_rate": 0.00025518292682926824,
      "loss": 2.9919,
      "step": 200
    },
    {
      "epoch": 1.164021164021164,
      "grad_norm": 0.8568211197853088,
      "learning_rate": 0.00024603658536585365,
      "loss": 2.905,
      "step": 220
    },
    {
      "epoch": 1.2698412698412698,
      "grad_norm": 1.0151021480560303,
      "learning_rate": 0.000236890243902439,
      "loss": 2.8501,
      "step": 240
    },
    {
      "epoch": 1.3756613756613756,
      "grad_norm": 1.184066653251648,
      "learning_rate": 0.00022774390243902436,
      "loss": 2.9187,
      "step": 260
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 1.203900933265686,
      "learning_rate": 0.00021859756097560972,
      "loss": 2.8284,
      "step": 280
    },
    {
      "epoch": 1.5873015873015874,
      "grad_norm": 1.1295077800750732,
      "learning_rate": 0.00020990853658536584,
      "loss": 2.8329,
      "step": 300
    },
    {
      "epoch": 1.693121693121693,
      "grad_norm": 1.2387043237686157,
      "learning_rate": 0.0002007621951219512,
      "loss": 2.8251,
      "step": 320
    },
    {
      "epoch": 1.798941798941799,
      "grad_norm": 0.9149441123008728,
      "learning_rate": 0.00019161585365853656,
      "loss": 2.8494,
      "step": 340
    },
    {
      "epoch": 1.9047619047619047,
      "grad_norm": 1.0098899602890015,
      "learning_rate": 0.00018246951219512195,
      "loss": 2.8973,
      "step": 360
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.6393818855285645,
      "eval_runtime": 2.3893,
      "eval_samples_per_second": 17.579,
      "eval_steps_per_second": 8.789,
      "step": 378
    },
    {
      "epoch": 2.0105820105820107,
      "grad_norm": 0.8324713110923767,
      "learning_rate": 0.0001733231707317073,
      "loss": 2.6188,
      "step": 380
    },
    {
      "epoch": 2.1164021164021163,
      "grad_norm": 1.0973880290985107,
      "learning_rate": 0.00016417682926829266,
      "loss": 2.7209,
      "step": 400
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 1.2067142724990845,
      "learning_rate": 0.00015503048780487802,
      "loss": 2.8802,
      "step": 420
    },
    {
      "epoch": 2.328042328042328,
      "grad_norm": 1.3191094398498535,
      "learning_rate": 0.0001458841463414634,
      "loss": 2.6833,
      "step": 440
    },
    {
      "epoch": 2.433862433862434,
      "grad_norm": 1.0430371761322021,
      "learning_rate": 0.00013673780487804876,
      "loss": 2.7077,
      "step": 460
    },
    {
      "epoch": 2.5396825396825395,
      "grad_norm": 1.167043924331665,
      "learning_rate": 0.00012759146341463412,
      "loss": 2.7201,
      "step": 480
    },
    {
      "epoch": 2.6455026455026456,
      "grad_norm": 1.0853570699691772,
      "learning_rate": 0.0001184451219512195,
      "loss": 2.8597,
      "step": 500
    },
    {
      "epoch": 2.751322751322751,
      "grad_norm": 1.2715704441070557,
      "learning_rate": 0.00010929878048780486,
      "loss": 2.6898,
      "step": 520
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 1.1871097087860107,
      "learning_rate": 0.00010015243902439025,
      "loss": 2.6077,
      "step": 540
    },
    {
      "epoch": 2.962962962962963,
      "grad_norm": 1.5462431907653809,
      "learning_rate": 9.10060975609756e-05,
      "loss": 2.8042,
      "step": 560
    },
    {
      "epoch": 3.0,
      "eval_loss": 2.607487201690674,
      "eval_runtime": 2.3955,
      "eval_samples_per_second": 17.533,
      "eval_steps_per_second": 8.766,
      "step": 567
    },
    {
      "epoch": 3.068783068783069,
      "grad_norm": 1.16291081905365,
      "learning_rate": 8.185975609756098e-05,
      "loss": 2.6819,
      "step": 580
    },
    {
      "epoch": 3.1746031746031744,
      "grad_norm": 1.2046189308166504,
      "learning_rate": 7.271341463414633e-05,
      "loss": 2.7164,
      "step": 600
    },
    {
      "epoch": 3.2804232804232805,
      "grad_norm": 1.4451225996017456,
      "learning_rate": 6.35670731707317e-05,
      "loss": 2.7335,
      "step": 620
    },
    {
      "epoch": 3.386243386243386,
      "grad_norm": 1.3499352931976318,
      "learning_rate": 5.442073170731707e-05,
      "loss": 2.7519,
      "step": 640
    },
    {
      "epoch": 3.492063492063492,
      "grad_norm": 1.1894453763961792,
      "learning_rate": 4.527439024390243e-05,
      "loss": 2.7964,
      "step": 660
    },
    {
      "epoch": 3.597883597883598,
      "grad_norm": 1.3277078866958618,
      "learning_rate": 3.61280487804878e-05,
      "loss": 2.7254,
      "step": 680
    },
    {
      "epoch": 3.7037037037037037,
      "grad_norm": 1.3310716152191162,
      "learning_rate": 2.698170731707317e-05,
      "loss": 2.6591,
      "step": 700
    },
    {
      "epoch": 3.8095238095238093,
      "grad_norm": 1.2061986923217773,
      "learning_rate": 1.7835365853658533e-05,
      "loss": 2.5448,
      "step": 720
    },
    {
      "epoch": 3.9153439153439153,
      "grad_norm": 1.3355391025543213,
      "learning_rate": 8.689024390243901e-06,
      "loss": 2.6465,
      "step": 740
    },
    {
      "epoch": 4.0,
      "eval_loss": 2.593783140182495,
      "eval_runtime": 2.4137,
      "eval_samples_per_second": 17.401,
      "eval_steps_per_second": 8.701,
      "step": 756
    }
  ],
  "logging_steps": 20,
  "max_steps": 756,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 934702926004224.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
