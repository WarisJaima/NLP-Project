{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 756,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.10582010582010581,
      "grad_norm": 1.2014250755310059,
      "learning_rate": 5.399999999999999e-05,
      "loss": 3.9375,
      "step": 20
    },
    {
      "epoch": 0.21164021164021163,
      "grad_norm": 2.2370166778564453,
      "learning_rate": 0.00011399999999999999,
      "loss": 3.951,
      "step": 40
    },
    {
      "epoch": 0.31746031746031744,
      "grad_norm": 1.4542174339294434,
      "learning_rate": 0.00017399999999999997,
      "loss": 3.6443,
      "step": 60
    },
    {
      "epoch": 0.42328042328042326,
      "grad_norm": 1.3978025913238525,
      "learning_rate": 0.000234,
      "loss": 3.3833,
      "step": 80
    },
    {
      "epoch": 0.5291005291005291,
      "grad_norm": 1.0825687646865845,
      "learning_rate": 0.000294,
      "loss": 3.2921,
      "step": 100
    },
    {
      "epoch": 0.6349206349206349,
      "grad_norm": 1.0870684385299683,
      "learning_rate": 0.0002917682926829268,
      "loss": 3.2237,
      "step": 120
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.916144847869873,
      "learning_rate": 0.00028262195121951216,
      "loss": 3.2114,
      "step": 140
    },
    {
      "epoch": 0.8465608465608465,
      "grad_norm": 0.8917463421821594,
      "learning_rate": 0.0002734756097560975,
      "loss": 3.2626,
      "step": 160
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 1.0151965618133545,
      "learning_rate": 0.0002643292682926829,
      "loss": 3.1555,
      "step": 180
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.887333393096924,
      "eval_runtime": 2.1579,
      "eval_samples_per_second": 19.463,
      "eval_steps_per_second": 9.732,
      "step": 189
    },
    {
      "epoch": 1.0582010582010581,
      "grad_norm": 1.1094049215316772,
      "learning_rate": 0.00025518292682926824,
      "loss": 3.0427,
      "step": 200
    },
    {
      "epoch": 1.164021164021164,
      "grad_norm": 1.0003918409347534,
      "learning_rate": 0.00024649390243902436,
      "loss": 2.839,
      "step": 220
    },
    {
      "epoch": 1.2698412698412698,
      "grad_norm": 0.9994333386421204,
      "learning_rate": 0.00023734756097560972,
      "loss": 3.1092,
      "step": 240
    },
    {
      "epoch": 1.3756613756613756,
      "grad_norm": 1.2214783430099487,
      "learning_rate": 0.00022820121951219508,
      "loss": 3.0887,
      "step": 260
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 1.0328418016433716,
      "learning_rate": 0.0002190548780487805,
      "loss": 3.0446,
      "step": 280
    },
    {
      "epoch": 1.5873015873015874,
      "grad_norm": 0.8776080012321472,
      "learning_rate": 0.00020990853658536584,
      "loss": 3.0923,
      "step": 300
    },
    {
      "epoch": 1.693121693121693,
      "grad_norm": 0.9492374062538147,
      "learning_rate": 0.0002007621951219512,
      "loss": 3.0031,
      "step": 320
    },
    {
      "epoch": 1.798941798941799,
      "grad_norm": 0.8856486678123474,
      "learning_rate": 0.00019161585365853656,
      "loss": 3.104,
      "step": 340
    },
    {
      "epoch": 1.9047619047619047,
      "grad_norm": 1.0002576112747192,
      "learning_rate": 0.00018246951219512195,
      "loss": 3.1108,
      "step": 360
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.841068983078003,
      "eval_runtime": 2.1903,
      "eval_samples_per_second": 19.175,
      "eval_steps_per_second": 9.588,
      "step": 378
    },
    {
      "epoch": 2.0105820105820107,
      "grad_norm": 0.9801055788993835,
      "learning_rate": 0.0001733231707317073,
      "loss": 3.0831,
      "step": 380
    },
    {
      "epoch": 2.1164021164021163,
      "grad_norm": 1.0711119174957275,
      "learning_rate": 0.00016463414634146343,
      "loss": 2.8724,
      "step": 400
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 1.2178807258605957,
      "learning_rate": 0.00015548780487804878,
      "loss": 3.0521,
      "step": 420
    },
    {
      "epoch": 2.328042328042328,
      "grad_norm": 1.0467957258224487,
      "learning_rate": 0.00014634146341463414,
      "loss": 2.9952,
      "step": 440
    },
    {
      "epoch": 2.433862433862434,
      "grad_norm": 1.1414175033569336,
      "learning_rate": 0.0001371951219512195,
      "loss": 2.9785,
      "step": 460
    },
    {
      "epoch": 2.5396825396825395,
      "grad_norm": 1.25816011428833,
      "learning_rate": 0.00012804878048780486,
      "loss": 3.0982,
      "step": 480
    },
    {
      "epoch": 2.6455026455026456,
      "grad_norm": 1.0751652717590332,
      "learning_rate": 0.00011890243902439024,
      "loss": 3.0104,
      "step": 500
    },
    {
      "epoch": 2.751322751322751,
      "grad_norm": 1.1260994672775269,
      "learning_rate": 0.0001097560975609756,
      "loss": 2.9635,
      "step": 520
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 1.2616180181503296,
      "learning_rate": 0.00010060975609756097,
      "loss": 2.9135,
      "step": 540
    },
    {
      "epoch": 2.962962962962963,
      "grad_norm": 1.1445567607879639,
      "learning_rate": 9.146341463414633e-05,
      "loss": 2.9866,
      "step": 560
    },
    {
      "epoch": 3.0,
      "eval_loss": 2.8240349292755127,
      "eval_runtime": 2.1561,
      "eval_samples_per_second": 19.48,
      "eval_steps_per_second": 9.74,
      "step": 567
    },
    {
      "epoch": 3.068783068783069,
      "grad_norm": 1.0600813627243042,
      "learning_rate": 8.231707317073171e-05,
      "loss": 2.8547,
      "step": 580
    },
    {
      "epoch": 3.1746031746031744,
      "grad_norm": 1.1232372522354126,
      "learning_rate": 7.317073170731707e-05,
      "loss": 2.9854,
      "step": 600
    },
    {
      "epoch": 3.2804232804232805,
      "grad_norm": 1.2490500211715698,
      "learning_rate": 6.402439024390243e-05,
      "loss": 2.9895,
      "step": 620
    },
    {
      "epoch": 3.386243386243386,
      "grad_norm": 1.2743834257125854,
      "learning_rate": 5.48780487804878e-05,
      "loss": 2.8761,
      "step": 640
    },
    {
      "epoch": 3.492063492063492,
      "grad_norm": 1.1364340782165527,
      "learning_rate": 4.6189024390243895e-05,
      "loss": 2.8701,
      "step": 660
    },
    {
      "epoch": 3.597883597883598,
      "grad_norm": 1.288025975227356,
      "learning_rate": 3.7042682926829266e-05,
      "loss": 2.9539,
      "step": 680
    },
    {
      "epoch": 3.7037037037037037,
      "grad_norm": 1.319175362586975,
      "learning_rate": 2.789634146341463e-05,
      "loss": 2.8574,
      "step": 700
    },
    {
      "epoch": 3.8095238095238093,
      "grad_norm": 1.1809215545654297,
      "learning_rate": 1.875e-05,
      "loss": 3.0045,
      "step": 720
    },
    {
      "epoch": 3.9153439153439153,
      "grad_norm": 1.3052438497543335,
      "learning_rate": 9.603658536585365e-06,
      "loss": 2.8996,
      "step": 740
    },
    {
      "epoch": 4.0,
      "eval_loss": 2.8168530464172363,
      "eval_runtime": 2.1439,
      "eval_samples_per_second": 19.591,
      "eval_steps_per_second": 9.795,
      "step": 756
    }
  ],
  "logging_steps": 20,
  "max_steps": 756,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 934702926004224.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
